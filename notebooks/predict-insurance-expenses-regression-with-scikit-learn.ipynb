{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Regression using scikit-learn\n","\n","### What is regression?\n","\n","**Regression** is when the feature to be predicted contains continuous values. Regression refers to the process of predicting a dependent variable by analyzing the relationship between other independent variables. There are several algorithms known to us that help us in excavating these relationships to better predict the value.\n","\n","### scikit-learn \n","\n","In this notebook, we'll use [scikit-learn](https://scikit-learn.org/stable/) to predict values. Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities. \n","\n","To help visualize what we are doing, we'll use visualizations with *matplotlib* python library.\n","\n","### Data\n"," \n","We'll continue to use the [`insurance.csv`](https://www.kaggle.com/noordeen/insurance-premium-prediction/download) file from you project assets, so if you have not already [`downloaded this file`](https://www.kaggle.com/noordeen/insurance-premium-prediction/download) to your local machine, and uploaded it to your project, do that now.\n","\n","<a id=\"top\"></a>\n","## Table of Contents\n","\n","1. [Load libraries](#load_libraries)\n","3. [Load data](#load_data)\n","4. [Prepare data for building regression model](#prepare_data)\n","5. [Build and test a multiple linear regression model](#model_lrc)"]},{"metadata":{},"cell_type":"markdown","source":["### Quick set of instructions to work through the notebook\n","\n","If you are new to Notebooks, here's a quick overview of how to work in this environment.\n","\n","1. The notebook has 2 types of cells - markdown (text) such as this and code such as the one below. \n","2. Each cell with code can be executed independently or together (see options under the Cell menu). When working in this notebook, we will be running one cell at a time because we need to make code changes to some of the cells.\n","3. To run the cell, position cursor in the code cell and click the Run (arrow) icon. The cell is running when you see the * next to it. Some cells have printable output.\n","4. Work through this notebook by reading the instructions and executing code cell by cell. Some cells will require modifications before you run them. "]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"load_libraries\"></a>\n","## 1. Load libraries\n","[Top](#top)\n","\n","Install python modules\n","NOTE! Some pip installs require a kernel restart.\n","The shell command pip install is used to install Python modules. Some installs require a kernel restart to complete. To avoid confusing errors, run the following cell once and then use the Kernel menu to restart the kernel before proceeding."]},{"metadata":{},"cell_type":"code","source":["!pip install -U scikit-learn\n","!pip install pandas==0.24.2\n","!pip install --user pandas_ml==0.6.1\n","!pip install matplotlib==3.1.0"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In the cell below we import the generic python libraries that will be used throughout the notebook"]},{"metadata":{},"cell_type":"code","source":["import pandas as pd, numpy as np\n","import sys\n","import io"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"load_data\"></a>\n","## 2. Load data\n","[Top](#top)\n","\n","A lot of data is **structured data**, which is data that is organized and formatted so it is easily readable, for example a table with variables as columns and records as rows, or key-value pairs in a noSQL database. As long as the data is formatted consistently and has multiple records with numbers, text and dates, you can probably read the data with [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html), an open-source Python package providing high-performance data manipulation and analysis.\n","\n","### 2.1 Load our data as a pandas data frame\n","\n","**<font color='red'><< FOLLOW THE INSTRUCTIONS BELOW TO LOAD THE DATASET >></font>**\n","\n","* Highlight the cell below by clicking it.\n","* Click the `10/01` \"Find data\" icon in the upper right of the notebook.\n","* Add the locally uploaded file `insurance.csv` by choosing the `Files` tab. Then choose the `insurance.csv`. Click `Insert to code` and choose `Insert Pandas DataFrame`.\n","* The code to bring the data into the notebook environment and create a Pandas DataFrame will be added to the cell below.\n","* Run the cell"]},{"metadata":{},"cell_type":"code","source":["# Place cursor below and insert the Pandas DataFrame for the Insurance Expense data\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 Update the variable for our Pandas dataframe\n","\n","We'll use the Pandas naming convention df for our DataFrame. Make sure that the cell below uses the name for the dataframe used above. For the locally uploaded file it should look like df_data_1 or df_data_2 or df_data_x. \n","\n","**<font color='red'><< UPDATE THE VARIABLE ASSIGNMENT TO THE VARIABLE GENERATED ABOVE. >></font>**"]},{"metadata":{},"cell_type":"code","source":["df_pd = df_data_1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"prepare_data\"></a>\n","## 3. Prepare data for building regression model\n","[Top](#top)\n","\n","Data preparation is a very important step in machine learning model building. This is because the model can perform well only when the data it is trained on is good and well prepared. Hence, this step consumes bulk of data scientist's time spent building models."]},{"metadata":{},"cell_type":"markdown","source":["### 3.1 Explore data\n","\n","Now let's have a look at the data that was loaded into the notebook. We will use pandas to understand the explore the dataset. Much detailed data exploration options were discussed in the previous module."]},{"metadata":{},"cell_type":"code","source":["print(\"The dataset contains columns of the following data types : \\n\" +str(df_pd.dtypes))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Verify that there are no missing values in the columns"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["print(\"The dataset contains following number of records for each of the columns : \\n\" +str(df_pd.count()))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["You can also identify if there are any missing values by running the following cell. In this case, we do not have any missing entries. "]},{"metadata":{},"cell_type":"code","source":["df_pd.isnull().any()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.2 Prepare categorical columns\n","\n","During this process, we identify categorical columns in the dataset. "]},{"metadata":{},"cell_type":"code","source":["# Defining the categorical columns \n","categoricalColumns = df_pd.select_dtypes(include=[np.object]).columns\n","\n","print(\"Categorical columns : \" )\n","print(categoricalColumns)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Categories needed to be indexed, which means the string labels are converted to indices or numbers. These label indices are encoded using One-hot encoding to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. This encoding allows algorithms which expect continuous features to use categorical features. We use the **OneHotEncoder** method from the *sklearn.preprocessing* library to implement this. "]},{"metadata":{},"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","onehot_categorical =  OneHotEncoder(handle_unknown='ignore')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We use the *SimpleImputer* method as an imputation transformer for completing missing values. Note that since this dataset has no missing values it will not have an impact for this example. We however show this to explain how values can be imputed using sklearn."]},{"metadata":{},"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","\n","impute_categorical = SimpleImputer(strategy=\"most_frequent\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["scikit-learn offers an API to sequentially apply a list of transforms and a final estimator - *sklearn.pipeline.Pipeline*. We create a pipeline and assemble the transformations we intend to apply on the categorical columns as shown below. "]},{"metadata":{},"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","\n","categorical_transformer = Pipeline(steps=[('impute',impute_categorical),('onehot',onehot_categorical)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. We define a *ColumnTransformer* and pass the pipeline we create in the cell above along with the column list we defined as well. "]},{"metadata":{},"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","\n","preprocessorForCategoricalColumns = ColumnTransformer(transformers=[('cat', categorical_transformer, categoricalColumns)],\n","                                            remainder=\"passthrough\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The transformation happens in the pipeline. We explicitly run the cell below to show what intermediate value looks like"]},{"metadata":{},"cell_type":"code","source":["df_pd_temp = preprocessorForCategoricalColumns.fit_transform(df_pd)\n","print(\"Categorical Data after transforming :\")\n","print(df_pd_temp)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.3 Prepare numerical columns\n","\n","During this process, we identify numerical columns in the dataset."]},{"metadata":{},"cell_type":"code","source":["# Defining the numerical columns \n","numericalColumns = [col for col in df_pd.select_dtypes(include=[np.float,np.int]).columns if col not in ['expenses']]\n","\n","print(\"Numerical columns : \" )\n","print(numericalColumns)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Following cell uses *StandardScaler* method from the the *sklearn.preprocessing* API.  Standardization of numerical fields refer to the process of removing the mean and scaling to unit variance. "]},{"metadata":{},"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler_numerical = StandardScaler()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The three cells below show, assembling the steps in the pipeline and creating a column transformers. The steps are very similar to section 3.2 shown above. "]},{"metadata":{},"cell_type":"code","source":["numerical_transformer = Pipeline(steps=[('scale',scaler_numerical)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["preprocessorForAllColumns = ColumnTransformer(transformers=[('cat', categorical_transformer, categoricalColumns),('num',numerical_transformer,numericalColumns)],\n","                                            remainder=\"passthrough\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df_pd_temp_2 = preprocessorForAllColumns.fit_transform(df_pd)\n","print(\"Data after transforming :\")\n","print(df_pd_temp_2)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.4 Prepare data frame for splitting data into train and test datasets\n","\n","We first divide the dataframe into *features* - that will contain the input columns that will be used to predict the final value. "]},{"metadata":{"scrolled":true},"cell_type":"code","source":["features = []\n","features = df_pd.drop(['expenses'], axis=1)\n","print('value of features : ' + str(features))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We then separate the column to predicted and mark it as the *label*"]},{"metadata":{},"cell_type":"code","source":["label = pd.DataFrame(df_pd, columns = ['expenses']) \n","label = df_pd['expenses']\n","\n","print(\" value of label : \" + str(label))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Now we will use *train_test_split* to split the feature and label dataframes into random train and test subsets. Unless explicit parameters are passed, the default is to split the dataset into 75% for training and 25% for testing. "]},{"metadata":{},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(features,label , random_state=0)\n","\n","print(\"Dimensions of datasets that will be used for training : Input features\"+str(X_train.shape)+ \n","      \" Output label\" + str(y_train.shape))\n","print(\"Dimensions of datasets that will be used for testing : Input features\"+str(X_test.shape)+ \n","      \" Output label\" + str(y_test.shape))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"model_lrc\"></a>\n","## 4. Build and test a multiple linear regression model\n","[Top](#top)\n","\n","\n","In a linear regression model, the variable to be predicted is dependent on only one other variable. This is calculated by using the formula that is generally used in calculating the slope of a line.\n","\n","y = w0 + w1*x1\n","\n","In the above equation, y refers to the target variable and x1 refers to the independent variable. w1 refers to the coeeficient that expresses the relationship between y and x1 is it also know as the slope. w0 is the constant cooefficient a.k.a the intercept. It refers to the constant offset that y will always be with respect to the independent variables.\n","\n","\n","Multiple linear regression is an extension to the simple linear regression. In this setup, the target value is dependant on more than one variable. The number of variables depends on the use case at hand. Usually a subject matter expert is involved in identifying the fields that will contribute towards better predicting the output feature.\n","\n","y = w0 + w1*x1 + w2*x2 + .... + wn*xn"]},{"metadata":{},"cell_type":"markdown","source":["### 4.1 Define linear regression model \n","\n","Since multiple linear regression assumes that output depends on more than one variable, we are assuming that it depends on all the 6 features. Data is split up into training and test sets. As an experiment, you can try to remove a few features and check if the model performs any better. "]},{"metadata":{},"cell_type":"markdown","source":["The cell below shows how to define a linear regression model using skleanr's *LinearRegression* method. "]},{"metadata":{"scrolled":true},"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","\n","model_name = 'Multiple Linear Regression'\n","\n","mlRegressor = LinearRegression()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We then add the model defined above to the pipeline which will be executed in the next cell."]},{"metadata":{},"cell_type":"code","source":["mlr_model = Pipeline(steps=[('preprocessorAll',preprocessorForAllColumns),('regressor', mlRegressor)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 4.2 Fit linear regression model\n","\n","We will now fit this linear model by passing in the train data obtained from the section above. This essentially runs the sequence of steps defined in the pipeline. "]},{"metadata":{},"cell_type":"code","source":["mlr_model.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 4.3 Predict insurance price using multiple linear regression model\n","\n","Now, its time to run our prediction on the model trained above. We do this by calling the *predict* method and passing the test features dataset. The output obtained is stored in an array marked as *y_pred_mlr*. "]},{"metadata":{},"cell_type":"code","source":["y_pred_mlr= mlr_model.predict(X_test)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 4.4 Evaluate multiple linear regression model\n","\n","The next few cells show how to quantify the quality of the predictions"]},{"metadata":{},"cell_type":"markdown","source":["Following are example attributes can be used to analyze the model performance. \n","\n","**intercept_** float or array of shape (n_targets,)\n","Independent term in the linear model. Set to 0.0 if fit_intercept = False.\n","\n","**coef_** array of shape (n_features, ) or (n_targets, n_features)\n","Estimated coefficients for the linear regression problem. If multiple targets are passed during the fit (y 2D), this is a 2D array of shape (n_targets, n_features), while if only one target is passed, this is a 1D array of length n_features."]},{"metadata":{},"cell_type":"code","source":["print(mlRegressor)\n","print('Intercept: \\n',mlRegressor.intercept_)\n","print('Coefficients: \\n', mlRegressor.coef_)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["There are several methods that [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) API offers us. We will now look at the *explained_variance_score* and the *mean_squared_error* method here as an example."]},{"metadata":{},"cell_type":"code","source":["from sklearn.metrics import explained_variance_score,mean_squared_error\n","\n","def model_metrics(regressor,y_test,y_pred):\n","    mse = mean_squared_error(y_test,y_pred)\n","    print(\"Mean squared error: %.2f\"\n","      % mse)\n","    \n","    e_v_s = explained_variance_score(y_test, y_pred)\n","    print('Explained variance score: %.2f' % e_v_s )\n","    return [mse, e_v_s]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["For explained variance, the best possible score is 1.0, lower values are worse."]},{"metadata":{},"cell_type":"code","source":["mlrMetrics = model_metrics(mlRegressor,y_test,y_pred_mlr)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Finally, we use *matplotlib* to visualize the actual vs predicted values of the insurance charges. "]},{"metadata":{},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import r2_score \n","\n","def two_d_compare(X_test,y_test,y_pred,model_name):\n","    area = (12 * np.random.rand(40))**2 \n","    plt.subplots(ncols=2, figsize=(10,4))\n","    plt.suptitle('Actual vs Predicted data : ' +model_name + '. Variance score: %.2f' % r2_score(y_test, y_pred))\n","\n","    plt.subplot(121)\n","    plt.scatter(X_test, y_test, alpha=0.8, color='#8CCB9B')\n","    plt.title('Actual')\n","\n","    plt.subplot(122)\n","    plt.scatter(X_test, y_pred,alpha=0.8, color='#E5E88B')\n","    plt.title('Predicted')\n","\n","    plt.show()\n","    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["two_d_compare(X_test['bmi'],y_test,y_pred_mlr,model_name)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<p><font size=-1 color=gray>\n","&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n","<p>\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n","except in compliance with the License. You may obtain a copy of the License at\n","https://www.apache.org/licenses/LICENSE-2.0\n","Unless required by applicable law or agreed to in writing, software distributed under the\n","License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n","express or implied. See the License for the specific language governing permissions and\n","limitations under the License.\n","</font></p>"]}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"name":"python3","display_name":"Python 3.7","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}